{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a3af096",
   "metadata": {},
   "source": [
    "# Leveraging Sentiment Analysis to Improve Airbnb Visualization Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2ec9f0",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e130c0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Java gateway process exited before sending its port number",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-bf372bc82d8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m spark = SparkSession.builder.appName(\"Datacamp Pyspark Tutorial\").config(\n\u001b[0;32m----> 4\u001b[0;31m     \"spark.memory.offHeap.enabled\", \"true\").config(\"spark.memory.offHeap.size\", \"10g\").getOrCreate()\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/listings.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mescape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    226\u001b[0m                             \u001b[0msparkConf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                         \u001b[0;31m# This SparkContext may be an existing one.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                         \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparkConf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m                     \u001b[0;31m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                     \u001b[0;31m# by all sessions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(cls, conf)\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \" is not allowed as it is a security risk.\")\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgateway\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlaunch_gateway\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjvm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/java_gateway.py\u001b[0m in \u001b[0;36mlaunch_gateway\u001b[0;34m(conf, popen_kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Java gateway process exited before sending its port number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Java gateway process exited before sending its port number"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "import pymongo\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Datacamp Pyspark Tutorial\").config(\n",
    "    \"spark.memory.offHeap.enabled\", \"true\").config(\"spark.memory.offHeap.size\", \"10g\").getOrCreate()\n",
    "df = spark.read.csv('./data/listings.csv', header=True, escape=\"\\\"\")\n",
    "df.show(5, 0)\n",
    "\n",
    "client = pymongo.MongoClient(\"localhost\", 27017)\n",
    "\n",
    "print(client)\n",
    "\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a88a07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE SUM IS HERE:  4950\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# https://github.com/RWaltersMA/mongo-spark-jupyter\n",
    "# master(\"spark://spark-master:7077\") --> If you add this master to the builder the master worker stops ...  :(\n",
    "# Create a SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"pyspark-notebook2\") \\\n",
    "    .config(\"spark.executor.memory\", \"1g\") \\\n",
    "    .config(\"spark.mongodb.input.uri\", \"mongodb://mongo:27017\") \\\n",
    "    .config(\"spark.mongodb.output.uri\", \"mongodb://mongo:27017\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.0\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "rdd = spark.sparkContext.parallelize(range(1, 100))\n",
    "\n",
    "print(\"THE SUM IS HERE: \", rdd.sum())\n",
    "\n",
    "# Stop the SparkSession\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9ba2bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82d1221c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import the necessary modules\n",
    "# from pyspark.sql import SparkSession\n",
    "# from pyspark.sql.functions import *\n",
    "\n",
    "# # https://github.com/RWaltersMA/mongo-spark-jupyter\n",
    "# # master(\"spark://spark-master:7077\") --> If you add this master to the builder the master worker stops ...  :(\n",
    "# # Create a SparkSession\n",
    "# spark = SparkSession \\\n",
    "#     .builder \\\n",
    "#     .appName(\"Spark NLP\") \\\n",
    "#     .config(\"spark.executor.memory\", \"1g\") \\\n",
    "#     .config(\"spark.mongodb.input.uri\", \"mongodb://mongo:27017\") \\\n",
    "#     .config(\"spark.mongodb.output.uri\", \"mongodb://mongo:27017\") \\\n",
    "#     .config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.0\") \\\n",
    "#     .master(\"local[*]\") \\\n",
    "#     .config(\"spark.driver.memory\",\"16G\") \\\n",
    "#     .config(\"spark.driver.maxResultSize\", \"0\") \\\n",
    "#     .config(\"spark.kryoserializer.buffer.max\", \"2000M\") \\\n",
    "#     .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:5.1.3\") \\\n",
    "#     .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fda5ff6",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Java gateway process exited before sending its port number",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ceea27afe426>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"spark.driver.maxResultSize\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"spark.kryoserializer.buffer.max\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"2000M\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"spark.jars.packages\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"com.johnsnowlabs.nlp:spark-nlp_2.12:5.1.3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    226\u001b[0m                             \u001b[0msparkConf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                         \u001b[0;31m# This SparkContext may be an existing one.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                         \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparkConf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m                     \u001b[0;31m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                     \u001b[0;31m# by all sessions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(cls, conf)\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \" is not allowed as it is a security risk.\")\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgateway\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlaunch_gateway\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjvm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/java_gateway.py\u001b[0m in \u001b[0;36mlaunch_gateway\u001b[0;34m(conf, popen_kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Java gateway process exited before sending its port number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Java gateway process exited before sending its port number"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark NLP\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"16G\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"0\") \\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"2000M\") \\\n",
    "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:5.1.3\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08667c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------------------------------------------------------------+-------+----------------+-------------------+----------------------------------+-----------------+-----------------+---------------+-----+--------------+-----------------+-----------+-----------------+------------------------------+----------------+---------------------+-----------+\n",
      "|id    |name                                                                      |host_id|host_name       |neighbourhood_group|neighbourhood                     |latitude         |longitude        |room_type      |price|minimum_nights|number_of_reviews|last_review|reviews_per_month|calculated_host_listings_count|availability_365|number_of_reviews_ltm|license    |\n",
      "+------+--------------------------------------------------------------------------+-------+----------------+-------------------+----------------------------------+-----------------+-----------------+---------------+-----+--------------+-----------------+-----------+-----------------+------------------------------+----------------+---------------------+-----------+\n",
      "|18674 |Rental unit in Barcelona · ★4.30 · 3 bedrooms · 6 beds · 2 baths          |71615  |Mireia And Maria|Eixample           |la Sagrada Família                |41.40556         |2.17262          |Entire home/apt|202  |1             |38               |2023-06-26 |0.30             |30                            |34              |8                    |HUTB-002062|\n",
      "|23197 |Rental unit in Sant Adria de Besos · ★4.77 · 3 bedrooms · 4 beds · 2 baths|90417  |Etain (Marnie)  |Sant Martí         |el Besòs i el Maresme             |41.41243172529066|2.219750335269476|Entire home/apt|255  |3             |73               |2023-08-15 |0.48             |2                             |150             |11                   |HUTB005057 |\n",
      "|32711 |Rental unit in Barcelona · ★4.46 · 2 bedrooms · 3 beds · 1.5 baths        |135703 |Nick            |Gràcia             |el Camp d'en Grassot i Gràcia Nova|41.40566         |2.17015          |Entire home/apt|171  |21            |95               |2023-08-18 |0.64             |3                             |310             |21                   |HUTB-001722|\n",
      "|171646|Rental unit in Barcelona · ★4.81 · 2 bedrooms · 2 beds · 1 bath           |400154 |Mireia          |Sant Martí         |el Clot                           |41.40671         |2.18592          |Entire home/apt|152  |3             |81               |2023-08-27 |0.65             |9                             |58              |22                   |HUTB-004663|\n",
      "|171816|Rental unit in Barcelona · ★4.71 · 2 bedrooms · 3 beds · 1 bath           |400154 |Mireia          |Sant Martí         |el Clot                           |41.40681         |2.18553          |Entire home/apt|150  |3             |49               |2023-08-27 |0.39             |9                             |67              |27                   |HUTB-004664|\n",
      "+------+--------------------------------------------------------------------------+-------+----------------+-------------------+----------------------------------+-----------------+-----------------+---------------+-----+--------------+-----------------+-----------+-----------------+------------------------------+----------------+---------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Number of rows:  18086\n"
     ]
    }
   ],
   "source": [
    "listings = spark.read.csv('./data/listings.csv', header=True, escape=\"\\\"\")\n",
    "listings.show(5, 0)\n",
    "\n",
    "print(\"Number of rows: \", listings.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a299dda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+--------------------+----------+-----------+-------------+-----------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|listing_id            |id                  |date      |reviewer_id|reviewer_name|comments                                                                                                                                       |\n",
      "+----------------------+--------------------+----------+-----------+-------------+-----------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|18674                 |4808211             |2013-05-27|4841196    |Caron        |Great location. Clean, spacious flat. Would recommend to anyone.                                                                               |\n",
      "|18674                 |10660311            |2014-03-02|11600277   |Juan Carlos  |Mi mejor recomendación para este departamento. Cuida todos los detalles, adicionalmente muy cómodo, limpio, funcional y situado perfectamente. |\n",
      "|18674                 |41087522            |2015-08-04|35231385   |Shlomi       |Big apartment, well equipped.                                                                                                                  |\n",
      "|<br/>Very good service| excellent location.|NULL      |NULL       |NULL         |NULL                                                                                                                                           |\n",
      "|<br/>Recommended.\"    |NULL                |NULL      |NULL       |NULL         |NULL                                                                                                                                           |\n",
      "+----------------------+--------------------+----------+-----------+-------------+-----------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Number of rows:  845479\n"
     ]
    }
   ],
   "source": [
    "reviews = spark.read.csv('./data/reviews.csv', header=True, escape=\"\\\"\")\n",
    "reviews.show(5, 0)\n",
    "\n",
    "print(\"Number of rows: \", reviews.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6db6744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------------------------------------------------------------+-------+----------------+-------------------+------------------+--------+---------+---------------+-----+--------------+-----------------+-----------+-----------------+------------------------------+----------------+---------------------+-----------+----------+---------+----------+-----------+-------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|id   |name                                                            |host_id|host_name       |neighbourhood_group|neighbourhood     |latitude|longitude|room_type      |price|minimum_nights|number_of_reviews|last_review|reviews_per_month|calculated_host_listings_count|availability_365|number_of_reviews_ltm|license    |listing_id|id       |date      |reviewer_id|reviewer_name|comments                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
      "+-----+----------------------------------------------------------------+-------+----------------+-------------------+------------------+--------+---------+---------------+-----+--------------+-----------------+-----------+-----------------+------------------------------+----------------+---------------------+-----------+----------+---------+----------+-----------+-------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|18674|Rental unit in Barcelona · ★4.30 · 3 bedrooms · 6 beds · 2 baths|71615  |Mireia And Maria|Eixample           |la Sagrada Família|41.40556|2.17262  |Entire home/apt|202  |1             |38               |2023-06-26 |0.30             |30                            |34              |8                    |HUTB-002062|18674     |4808211  |2013-05-27|4841196    |Caron        |Great location. Clean, spacious flat. Would recommend to anyone.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
      "|18674|Rental unit in Barcelona · ★4.30 · 3 bedrooms · 6 beds · 2 baths|71615  |Mireia And Maria|Eixample           |la Sagrada Família|41.40556|2.17262  |Entire home/apt|202  |1             |38               |2023-06-26 |0.30             |30                            |34              |8                    |HUTB-002062|18674     |10660311 |2014-03-02|11600277   |Juan Carlos  |Mi mejor recomendación para este departamento. Cuida todos los detalles, adicionalmente muy cómodo, limpio, funcional y situado perfectamente.                                                                                                                                                                                                                                                                                                                                                                                                   |\n",
      "|18674|Rental unit in Barcelona · ★4.30 · 3 bedrooms · 6 beds · 2 baths|71615  |Mireia And Maria|Eixample           |la Sagrada Família|41.40556|2.17262  |Entire home/apt|202  |1             |38               |2023-06-26 |0.30             |30                            |34              |8                    |HUTB-002062|18674     |41087522 |2015-08-04|35231385   |Shlomi       |Big apartment, well equipped.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n",
      "|18674|Rental unit in Barcelona · ★4.30 · 3 bedrooms · 6 beds · 2 baths|71615  |Mireia And Maria|Eixample           |la Sagrada Família|41.40556|2.17262  |Entire home/apt|202  |1             |38               |2023-06-26 |0.30             |30                            |34              |8                    |HUTB-002062|18674     |81000756 |2016-06-20|23223644   |Joost        |The Check in was fast and flexible. The price is fair, because the flat ist big enough for 8 people if you are flexible as well. We were the in a time where it wasn't so hot outside, so I have no idea how hot it can get inside. This was my second Airbnb stay so I can't compare it so good with other apartments but I would wish me, that the owner, offers the guests more toilet paper  etc. . Because if it is a short stay, you don't want to buy all the staff in big packages. <br/>All in all we are very happy with this decision |\n",
      "|18674|Rental unit in Barcelona · ★4.30 · 3 bedrooms · 6 beds · 2 baths|71615  |Mireia And Maria|Eixample           |la Sagrada Família|41.40556|2.17262  |Entire home/apt|202  |1             |38               |2023-06-26 |0.30             |30                            |34              |8                    |HUTB-002062|18674     |278588962|2018-06-18|4756672    |Marius       |Great location and enough space in the apartment for 7 people. Although the mattresses were a bit too soft and the house is quite noisy, its a solid choice for a big group of people for a weekend in barcelona.                                                                                                                                                                                                                                                                                                                                |\n",
      "+-----+----------------------------------------------------------------+-------+----------------+-------------------+------------------+--------+---------+---------------+-----+--------------+-----------------+-----------+-----------------+------------------------------+----------------+---------------------+-----------+----------+---------+----------+-----------+-------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Number of rows:  763592\n"
     ]
    }
   ],
   "source": [
    "# join listings and reviews on the id and listing_id columns\n",
    "listings_reviews = listings.join(reviews, listings.id == reviews.listing_id)\n",
    "listings_reviews.show(5, 0)\n",
    "\n",
    "print(\"Number of rows: \", listings_reviews.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "398fb2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+---------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|listing_id|latitude|longitude|comments                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
      "+----------+--------+---------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|18674     |41.40556|2.17262  |Great location. Clean, spacious flat. Would recommend to anyone.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
      "|18674     |41.40556|2.17262  |Mi mejor recomendación para este departamento. Cuida todos los detalles, adicionalmente muy cómodo, limpio, funcional y situado perfectamente.                                                                                                                                                                                                                                                                                                                                                                                                   |\n",
      "|18674     |41.40556|2.17262  |Big apartment, well equipped.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n",
      "|18674     |41.40556|2.17262  |The Check in was fast and flexible. The price is fair, because the flat ist big enough for 8 people if you are flexible as well. We were the in a time where it wasn't so hot outside, so I have no idea how hot it can get inside. This was my second Airbnb stay so I can't compare it so good with other apartments but I would wish me, that the owner, offers the guests more toilet paper  etc. . Because if it is a short stay, you don't want to buy all the staff in big packages. <br/>All in all we are very happy with this decision |\n",
      "|18674     |41.40556|2.17262  |Great location and enough space in the apartment for 7 people. Although the mattresses were a bit too soft and the house is quite noisy, its a solid choice for a big group of people for a weekend in barcelona.                                                                                                                                                                                                                                                                                                                                |\n",
      "+----------+--------+---------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# keep only id, latitude, longitude, and comments\n",
    "listings_reviews = listings_reviews.select(\n",
    "    \"listing_id\", \"latitude\", \"longitude\", \"comments\")\n",
    "listings_reviews.show(5, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f27d21f",
   "metadata": {},
   "source": [
    "## Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f6fbe2",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1961a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfhub_use download started this may take some time.\n",
      "Approximate size to download 923.7 MB\n",
      "[ — ]\n",
      "An error occurred while calling z:com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader.downloadModel.\n",
      ": java.lang.UnsatisfiedLinkError: no jnitensorflow in java.library.path: /usr/java/packages/lib:/usr/lib/aarch64-linux-gnu/jni:/lib/aarch64-linux-gnu:/usr/lib/aarch64-linux-gnu:/usr/lib/jni:/lib:/usr/lib\n",
      "\tat java.base/java.lang.ClassLoader.loadLibrary(ClassLoader.java:2434)\n",
      "\tat java.base/java.lang.Runtime.loadLibrary0(Runtime.java:818)\n",
      "\tat java.base/java.lang.System.loadLibrary(System.java:1989)\n",
      "\tat org.bytedeco.javacpp.Loader.loadLibrary(Loader.java:1738)\n",
      "\tat org.bytedeco.javacpp.Loader.load(Loader.java:1345)\n",
      "\tat org.bytedeco.javacpp.Loader.load(Loader.java:1157)\n",
      "\tat org.bytedeco.javacpp.Loader.load(Loader.java:1133)\n",
      "\tat org.tensorflow.internal.c_api.global.tensorflow.<clinit>(tensorflow.java:12)\n",
      "\tat java.base/java.lang.Class.forName0(Native Method)\n",
      "\tat java.base/java.lang.Class.forName(Class.java:467)\n",
      "\tat org.bytedeco.javacpp.Loader.load(Loader.java:1212)\n",
      "\tat org.bytedeco.javacpp.Loader.load(Loader.java:1157)\n",
      "\tat org.bytedeco.javacpp.Loader.load(Loader.java:1149)\n",
      "\tat org.tensorflow.NativeLibrary.load(NativeLibrary.java:64)\n",
      "\tat org.tensorflow.TensorFlow.<clinit>(TensorFlow.java:156)\n",
      "\tat java.base/java.lang.Class.forName0(Native Method)\n",
      "\tat java.base/java.lang.Class.forName(Class.java:375)\n",
      "\tat org.tensorflow.Graph.<clinit>(Graph.java:1341)\n",
      "\tat com.johnsnowlabs.ml.tensorflow.TensorflowWrapper$.readGraph(TensorflowWrapper.scala:415)\n",
      "\tat com.johnsnowlabs.ml.tensorflow.TensorflowWrapper$.unpackWithoutBundle(TensorflowWrapper.scala:330)\n",
      "\tat com.johnsnowlabs.ml.tensorflow.TensorflowWrapper$.readWithSP(TensorflowWrapper.scala:542)\n",
      "\tat com.johnsnowlabs.ml.tensorflow.ReadTensorflowModel.readTensorflowWithSPModel(TensorflowSerializeModel.scala:195)\n",
      "\tat com.johnsnowlabs.ml.tensorflow.ReadTensorflowModel.readTensorflowWithSPModel$(TensorflowSerializeModel.scala:162)\n",
      "\tat com.johnsnowlabs.nlp.embeddings.UniversalSentenceEncoder$.readTensorflowWithSPModel(UniversalSentenceEncoder.scala:380)\n",
      "\tat com.johnsnowlabs.nlp.embeddings.ReadUSEDLModel.readModel(UniversalSentenceEncoder.scala:332)\n",
      "\tat com.johnsnowlabs.nlp.embeddings.ReadUSEDLModel.readModel$(UniversalSentenceEncoder.scala:329)\n",
      "\tat com.johnsnowlabs.nlp.embeddings.UniversalSentenceEncoder$.readModel(UniversalSentenceEncoder.scala:380)\n",
      "\tat com.johnsnowlabs.nlp.embeddings.ReadUSEDLModel.$anonfun$$init$$1(UniversalSentenceEncoder.scala:336)\n",
      "\tat com.johnsnowlabs.nlp.embeddings.ReadUSEDLModel.$anonfun$$init$$1$adapted(UniversalSentenceEncoder.scala:336)\n",
      "\tat com.johnsnowlabs.nlp.ParamsAndFeaturesReadable.$anonfun$onRead$1(ParamsAndFeaturesReadable.scala:50)\n",
      "\tat com.johnsnowlabs.nlp.ParamsAndFeaturesReadable.$anonfun$onRead$1$adapted(ParamsAndFeaturesReadable.scala:49)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat com.johnsnowlabs.nlp.ParamsAndFeaturesReadable.onRead(ParamsAndFeaturesReadable.scala:49)\n",
      "\tat com.johnsnowlabs.nlp.ParamsAndFeaturesReadable.$anonfun$read$1(ParamsAndFeaturesReadable.scala:61)\n",
      "\tat com.johnsnowlabs.nlp.ParamsAndFeaturesReadable.$anonfun$read$1$adapted(ParamsAndFeaturesReadable.scala:61)\n",
      "\tat com.johnsnowlabs.nlp.FeaturesReader.load(ParamsAndFeaturesReadable.scala:38)\n",
      "\tat com.johnsnowlabs.nlp.FeaturesReader.load(ParamsAndFeaturesReadable.scala:24)\n",
      "\tat com.johnsnowlabs.nlp.pretrained.ResourceDownloader$.downloadModel(ResourceDownloader.scala:518)\n",
      "\tat com.johnsnowlabs.nlp.pretrained.ResourceDownloader$.downloadModel(ResourceDownloader.scala:510)\n",
      "\tat com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader$.downloadModel(ResourceDownloader.scala:709)\n",
      "\tat com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader.downloadModel(ResourceDownloader.scala)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.lang.UnsatisfiedLinkError: Could not find jnitensorflow in class, module, and library paths.\n",
      "\tat org.bytedeco.javacpp.Loader.loadLibrary(Loader.java:1705)\n",
      "\t... 51 more\n",
      "[OK!]\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader.downloadModel.\n: java.lang.UnsatisfiedLinkError: no jnitensorflow in java.library.path: /usr/java/packages/lib:/usr/lib/aarch64-linux-gnu/jni:/lib/aarch64-linux-gnu:/usr/lib/aarch64-linux-gnu:/usr/lib/jni:/lib:/usr/lib\n\tat java.base/java.lang.ClassLoader.loadLibrary(ClassLoader.java:2434)\n\tat java.base/java.lang.Runtime.loadLibrary0(Runtime.java:818)\n\tat java.base/java.lang.System.loadLibrary(System.java:1989)\n\tat org.bytedeco.javacpp.Loader.loadLibrary(Loader.java:1738)\n\tat org.bytedeco.javacpp.Loader.load(Loader.java:1345)\n\tat org.bytedeco.javacpp.Loader.load(Loader.java:1157)\n\tat org.bytedeco.javacpp.Loader.load(Loader.java:1133)\n\tat org.tensorflow.internal.c_api.global.tensorflow.<clinit>(tensorflow.java:12)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:467)\n\tat org.bytedeco.javacpp.Loader.load(Loader.java:1212)\n\tat org.bytedeco.javacpp.Loader.load(Loader.java:1157)\n\tat org.bytedeco.javacpp.Loader.load(Loader.java:1149)\n\tat org.tensorflow.NativeLibrary.load(NativeLibrary.java:64)\n\tat org.tensorflow.TensorFlow.<clinit>(TensorFlow.java:156)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat org.tensorflow.Graph.<clinit>(Graph.java:1341)\n\tat com.johnsnowlabs.ml.tensorflow.TensorflowWrapper$.readGraph(TensorflowWrapper.scala:415)\n\tat com.johnsnowlabs.ml.tensorflow.TensorflowWrapper$.unpackWithoutBundle(TensorflowWrapper.scala:330)\n\tat com.johnsnowlabs.ml.tensorflow.TensorflowWrapper$.readWithSP(TensorflowWrapper.scala:542)\n\tat com.johnsnowlabs.ml.tensorflow.ReadTensorflowModel.readTensorflowWithSPModel(TensorflowSerializeModel.scala:195)\n\tat com.johnsnowlabs.ml.tensorflow.ReadTensorflowModel.readTensorflowWithSPModel$(TensorflowSerializeModel.scala:162)\n\tat com.johnsnowlabs.nlp.embeddings.UniversalSentenceEncoder$.readTensorflowWithSPModel(UniversalSentenceEncoder.scala:380)\n\tat com.johnsnowlabs.nlp.embeddings.ReadUSEDLModel.readModel(UniversalSentenceEncoder.scala:332)\n\tat com.johnsnowlabs.nlp.embeddings.ReadUSEDLModel.readModel$(UniversalSentenceEncoder.scala:329)\n\tat com.johnsnowlabs.nlp.embeddings.UniversalSentenceEncoder$.readModel(UniversalSentenceEncoder.scala:380)\n\tat com.johnsnowlabs.nlp.embeddings.ReadUSEDLModel.$anonfun$$init$$1(UniversalSentenceEncoder.scala:336)\n\tat com.johnsnowlabs.nlp.embeddings.ReadUSEDLModel.$anonfun$$init$$1$adapted(UniversalSentenceEncoder.scala:336)\n\tat com.johnsnowlabs.nlp.ParamsAndFeaturesReadable.$anonfun$onRead$1(ParamsAndFeaturesReadable.scala:50)\n\tat com.johnsnowlabs.nlp.ParamsAndFeaturesReadable.$anonfun$onRead$1$adapted(ParamsAndFeaturesReadable.scala:49)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat com.johnsnowlabs.nlp.ParamsAndFeaturesReadable.onRead(ParamsAndFeaturesReadable.scala:49)\n\tat com.johnsnowlabs.nlp.ParamsAndFeaturesReadable.$anonfun$read$1(ParamsAndFeaturesReadable.scala:61)\n\tat com.johnsnowlabs.nlp.ParamsAndFeaturesReadable.$anonfun$read$1$adapted(ParamsAndFeaturesReadable.scala:61)\n\tat com.johnsnowlabs.nlp.FeaturesReader.load(ParamsAndFeaturesReadable.scala:38)\n\tat com.johnsnowlabs.nlp.FeaturesReader.load(ParamsAndFeaturesReadable.scala:24)\n\tat com.johnsnowlabs.nlp.pretrained.ResourceDownloader$.downloadModel(ResourceDownloader.scala:518)\n\tat com.johnsnowlabs.nlp.pretrained.ResourceDownloader$.downloadModel(ResourceDownloader.scala:510)\n\tat com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader$.downloadModel(ResourceDownloader.scala:709)\n\tat com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader.downloadModel(ResourceDownloader.scala)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:833)\nCaused by: java.lang.UnsatisfiedLinkError: Could not find jnitensorflow in class, module, and library paths.\n\tat org.bytedeco.javacpp.Loader.loadLibrary(Loader.java:1705)\n\t... 51 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/Users/matteocirca/projects/airbnb-sentiment-analysis/app/TEST.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/matteocirca/projects/airbnb-sentiment-analysis/app/TEST.ipynb#X16sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpyspark\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msql\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctions\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mF\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/matteocirca/projects/airbnb-sentiment-analysis/app/TEST.ipynb#X16sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m documentAssembler \u001b[39m=\u001b[39m DocumentAssembler()\\\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matteocirca/projects/airbnb-sentiment-analysis/app/TEST.ipynb#X16sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m.\u001b[39msetInputCol(\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m)\\\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matteocirca/projects/airbnb-sentiment-analysis/app/TEST.ipynb#X16sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m.\u001b[39msetOutputCol(\u001b[39m\"\u001b[39m\u001b[39mdocument\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/matteocirca/projects/airbnb-sentiment-analysis/app/TEST.ipynb#X16sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m use \u001b[39m=\u001b[39m UniversalSentenceEncoder\u001b[39m.\u001b[39;49mpretrained(\u001b[39m\"\u001b[39;49m\u001b[39mtfhub_use\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39men\u001b[39;49m\u001b[39m\"\u001b[39;49m)\\\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matteocirca/projects/airbnb-sentiment-analysis/app/TEST.ipynb#X16sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39m.\u001b[39msetInputCols([\u001b[39m\"\u001b[39m\u001b[39mdocument\u001b[39m\u001b[39m\"\u001b[39m])\\\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matteocirca/projects/airbnb-sentiment-analysis/app/TEST.ipynb#X16sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39m.\u001b[39msetOutputCol(\u001b[39m\"\u001b[39m\u001b[39msentence_embeddings\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matteocirca/projects/airbnb-sentiment-analysis/app/TEST.ipynb#X16sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m sentimentdl \u001b[39m=\u001b[39m SentimentDLModel\u001b[39m.\u001b[39mpretrained(\u001b[39m\"\u001b[39m\u001b[39msentimentdl_use_twitter\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39men\u001b[39m\u001b[39m\"\u001b[39m)\\\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matteocirca/projects/airbnb-sentiment-analysis/app/TEST.ipynb#X16sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39m.\u001b[39msetInputCols([\u001b[39m\"\u001b[39m\u001b[39msentence_embeddings\u001b[39m\u001b[39m\"\u001b[39m])\\\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matteocirca/projects/airbnb-sentiment-analysis/app/TEST.ipynb#X16sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39m.\u001b[39msetOutputCol(\u001b[39m\"\u001b[39m\u001b[39msentiment\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matteocirca/projects/airbnb-sentiment-analysis/app/TEST.ipynb#X16sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m nlpPipeline \u001b[39m=\u001b[39m Pipeline(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matteocirca/projects/airbnb-sentiment-analysis/app/TEST.ipynb#X16sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     stages\u001b[39m=\u001b[39m[\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matteocirca/projects/airbnb-sentiment-analysis/app/TEST.ipynb#X16sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m         documentAssembler,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matteocirca/projects/airbnb-sentiment-analysis/app/TEST.ipynb#X16sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m         use,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matteocirca/projects/airbnb-sentiment-analysis/app/TEST.ipynb#X16sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m         sentimentdl\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matteocirca/projects/airbnb-sentiment-analysis/app/TEST.ipynb#X16sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     ])\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sparknlp/annotator/embeddings/universal_sentence_encoder.py:211\u001b[0m, in \u001b[0;36mUniversalSentenceEncoder.pretrained\u001b[0;34m(name, lang, remote_loc)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Downloads and loads a pretrained model.\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \n\u001b[1;32m    195\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[39m    The restored model\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msparknlp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpretrained\u001b[39;00m \u001b[39mimport\u001b[39;00m ResourceDownloader\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m ResourceDownloader\u001b[39m.\u001b[39;49mdownloadModel(UniversalSentenceEncoder, name, lang, remote_loc)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sparknlp/pretrained/resource_downloader.py:99\u001b[0m, in \u001b[0;36mResourceDownloader.downloadModel\u001b[0;34m(reader, name, language, remote_loc, j_dwn)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m Py4JJavaError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     sys\u001b[39m.\u001b[39mstdout\u001b[39m.\u001b[39mwrite(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e))\n\u001b[0;32m---> 99\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    100\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    101\u001b[0m     stop_threads \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sparknlp/pretrained/resource_downloader.py:96\u001b[0m, in \u001b[0;36mResourceDownloader.downloadModel\u001b[0;34m(reader, name, language, remote_loc, j_dwn)\u001b[0m\n\u001b[1;32m     94\u001b[0m t1\u001b[39m.\u001b[39mstart()\n\u001b[1;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     j_obj \u001b[39m=\u001b[39m _internal\u001b[39m.\u001b[39;49m_DownloadModel(reader\u001b[39m.\u001b[39;49mname, name, language, remote_loc, j_dwn)\u001b[39m.\u001b[39mapply()\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m Py4JJavaError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     sys\u001b[39m.\u001b[39mstdout\u001b[39m.\u001b[39mwrite(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sparknlp/internal/__init__.py:349\u001b[0m, in \u001b[0;36m_DownloadModel.__init__\u001b[0;34m(self, reader, name, language, remote_loc, validator)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, reader, name, language, remote_loc, validator):\n\u001b[0;32m--> 349\u001b[0m     \u001b[39msuper\u001b[39;49m(_DownloadModel, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mcom.johnsnowlabs.nlp.pretrained.\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m validator \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m.downloadModel\u001b[39;49m\u001b[39m\"\u001b[39;49m, reader,\n\u001b[1;32m    350\u001b[0m                                          name, language, remote_loc)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sparknlp/internal/extended_java_wrapper.py:27\u001b[0m, in \u001b[0;36mExtendedJavaWrapper.__init__\u001b[0;34m(self, java_obj, *args)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39msuper\u001b[39m(ExtendedJavaWrapper, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(java_obj)\n\u001b[1;32m     26\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msc \u001b[39m=\u001b[39m SparkContext\u001b[39m.\u001b[39m_active_spark_context\n\u001b[0;32m---> 27\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_java_obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnew_java_obj(java_obj, \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m     28\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjava_obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_java_obj\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sparknlp/internal/extended_java_wrapper.py:37\u001b[0m, in \u001b[0;36mExtendedJavaWrapper.new_java_obj\u001b[0;34m(self, java_class, *args)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnew_java_obj\u001b[39m(\u001b[39mself\u001b[39m, java_class, \u001b[39m*\u001b[39margs):\n\u001b[0;32m---> 37\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_new_java_obj(java_class, \u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/ml/wrapper.py:86\u001b[0m, in \u001b[0;36mJavaWrapper._new_java_obj\u001b[0;34m(java_class, *args)\u001b[0m\n\u001b[1;32m     84\u001b[0m     java_obj \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(java_obj, name)\n\u001b[1;32m     85\u001b[0m java_args \u001b[39m=\u001b[39m [_py2java(sc, arg) \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m args]\n\u001b[0;32m---> 86\u001b[0m \u001b[39mreturn\u001b[39;00m java_obj(\u001b[39m*\u001b[39;49mjava_args)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(temp_arg, \u001b[39m\"\u001b[39m\u001b[39m_detach\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/errors/exceptions/captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdeco\u001b[39m(\u001b[39m*\u001b[39ma: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    178\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49ma, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m    180\u001b[0m     \u001b[39mexcept\u001b[39;00m Py4JJavaError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    181\u001b[0m         converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[39m=\u001b[39m OUTPUT_CONVERTER[\u001b[39mtype\u001b[39m](answer[\u001b[39m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m answer[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m. Trace:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{3}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader.downloadModel.\n: java.lang.UnsatisfiedLinkError: no jnitensorflow in java.library.path: /usr/java/packages/lib:/usr/lib/aarch64-linux-gnu/jni:/lib/aarch64-linux-gnu:/usr/lib/aarch64-linux-gnu:/usr/lib/jni:/lib:/usr/lib\n\tat java.base/java.lang.ClassLoader.loadLibrary(ClassLoader.java:2434)\n\tat java.base/java.lang.Runtime.loadLibrary0(Runtime.java:818)\n\tat java.base/java.lang.System.loadLibrary(System.java:1989)\n\tat org.bytedeco.javacpp.Loader.loadLibrary(Loader.java:1738)\n\tat org.bytedeco.javacpp.Loader.load(Loader.java:1345)\n\tat org.bytedeco.javacpp.Loader.load(Loader.java:1157)\n\tat org.bytedeco.javacpp.Loader.load(Loader.java:1133)\n\tat org.tensorflow.internal.c_api.global.tensorflow.<clinit>(tensorflow.java:12)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:467)\n\tat org.bytedeco.javacpp.Loader.load(Loader.java:1212)\n\tat org.bytedeco.javacpp.Loader.load(Loader.java:1157)\n\tat org.bytedeco.javacpp.Loader.load(Loader.java:1149)\n\tat org.tensorflow.NativeLibrary.load(NativeLibrary.java:64)\n\tat org.tensorflow.TensorFlow.<clinit>(TensorFlow.java:156)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat org.tensorflow.Graph.<clinit>(Graph.java:1341)\n\tat com.johnsnowlabs.ml.tensorflow.TensorflowWrapper$.readGraph(TensorflowWrapper.scala:415)\n\tat com.johnsnowlabs.ml.tensorflow.TensorflowWrapper$.unpackWithoutBundle(TensorflowWrapper.scala:330)\n\tat com.johnsnowlabs.ml.tensorflow.TensorflowWrapper$.readWithSP(TensorflowWrapper.scala:542)\n\tat com.johnsnowlabs.ml.tensorflow.ReadTensorflowModel.readTensorflowWithSPModel(TensorflowSerializeModel.scala:195)\n\tat com.johnsnowlabs.ml.tensorflow.ReadTensorflowModel.readTensorflowWithSPModel$(TensorflowSerializeModel.scala:162)\n\tat com.johnsnowlabs.nlp.embeddings.UniversalSentenceEncoder$.readTensorflowWithSPModel(UniversalSentenceEncoder.scala:380)\n\tat com.johnsnowlabs.nlp.embeddings.ReadUSEDLModel.readModel(UniversalSentenceEncoder.scala:332)\n\tat com.johnsnowlabs.nlp.embeddings.ReadUSEDLModel.readModel$(UniversalSentenceEncoder.scala:329)\n\tat com.johnsnowlabs.nlp.embeddings.UniversalSentenceEncoder$.readModel(UniversalSentenceEncoder.scala:380)\n\tat com.johnsnowlabs.nlp.embeddings.ReadUSEDLModel.$anonfun$$init$$1(UniversalSentenceEncoder.scala:336)\n\tat com.johnsnowlabs.nlp.embeddings.ReadUSEDLModel.$anonfun$$init$$1$adapted(UniversalSentenceEncoder.scala:336)\n\tat com.johnsnowlabs.nlp.ParamsAndFeaturesReadable.$anonfun$onRead$1(ParamsAndFeaturesReadable.scala:50)\n\tat com.johnsnowlabs.nlp.ParamsAndFeaturesReadable.$anonfun$onRead$1$adapted(ParamsAndFeaturesReadable.scala:49)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat com.johnsnowlabs.nlp.ParamsAndFeaturesReadable.onRead(ParamsAndFeaturesReadable.scala:49)\n\tat com.johnsnowlabs.nlp.ParamsAndFeaturesReadable.$anonfun$read$1(ParamsAndFeaturesReadable.scala:61)\n\tat com.johnsnowlabs.nlp.ParamsAndFeaturesReadable.$anonfun$read$1$adapted(ParamsAndFeaturesReadable.scala:61)\n\tat com.johnsnowlabs.nlp.FeaturesReader.load(ParamsAndFeaturesReadable.scala:38)\n\tat com.johnsnowlabs.nlp.FeaturesReader.load(ParamsAndFeaturesReadable.scala:24)\n\tat com.johnsnowlabs.nlp.pretrained.ResourceDownloader$.downloadModel(ResourceDownloader.scala:518)\n\tat com.johnsnowlabs.nlp.pretrained.ResourceDownloader$.downloadModel(ResourceDownloader.scala:510)\n\tat com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader$.downloadModel(ResourceDownloader.scala:709)\n\tat com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader.downloadModel(ResourceDownloader.scala)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:833)\nCaused by: java.lang.UnsatisfiedLinkError: Could not find jnitensorflow in class, module, and library paths.\n\tat org.bytedeco.javacpp.Loader.loadLibrary(Loader.java:1705)\n\t... 51 more\n"
     ]
    }
   ],
   "source": [
    "# Import the required modules and classes\n",
    "from sparknlp.base import DocumentAssembler, Pipeline, LightPipeline\n",
    "from sparknlp.annotator import (\n",
    "    UniversalSentenceEncoder,\n",
    "    SentimentDLModel\n",
    ")\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "documentAssembler = DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "use = UniversalSentenceEncoder.pretrained(\"tfhub_use\", \"en\")\\\n",
    "    .setInputCols([\"document\"])\\\n",
    "    .setOutputCol(\"sentence_embeddings\")\n",
    "\n",
    "sentimentdl = SentimentDLModel.pretrained(\"sentimentdl_use_twitter\", \"en\")\\\n",
    "    .setInputCols([\"sentence_embeddings\"])\\\n",
    "    .setOutputCol(\"sentiment\")\n",
    "\n",
    "nlpPipeline = Pipeline(\n",
    "    stages=[\n",
    "        documentAssembler,\n",
    "        use,\n",
    "        sentimentdl\n",
    "    ])\n",
    "\n",
    "text_list = [\n",
    "    \"\"\"@Mbjthegreat i really dont want AT&amp;T phone service..they suck when it comes to having a signal\"\"\",\n",
    "    \"\"\"holy crap. I take a nap for 4 hours and Pitchfork blows up my twitter dashboard. I wish I was at Coachella.\"\"\",\n",
    "    \"\"\"@Susy412 he is working today  ive tried that still not working..... hmmmm!! im rubbish with computers haha!\"\"\",\n",
    "    \"\"\"Brand New Canon EOS 50D 15MP DSLR Camera Canon 17-85mm IS Lens ...: Web Technology Thread, Brand New Canon EOS 5.. http://u.mavrev.com/5a3t\"\"\",\n",
    "    \"\"\"Watching a programme about the life of Hitler, its only enhancing my geekiness of history.\"\"\",\n",
    "    \"\"\"GM says expects announcment on sale of Hummer soon - Reuters: WDSUGM says expects announcment on sale of Hummer .. http://bit.ly/4E1Fv\"\"\",\n",
    "    \"\"\"@accannis @edog1203 Great Stanford course. Thanks for making it available to the public! Really helpful and informative for starting off!\"\"\",\n",
    "    \"\"\"@the_real_usher LeBron is cool.  I like his personality...he has good character.\"\"\",\n",
    "    \"\"\"@sketchbug Lebron is a hometown hero to me, lol I love the Lakers but let's go Cavs, lol\"\"\",\n",
    "    \"\"\"@PDubyaD right!!! LOL we'll get there!! I have high expectations, Warren Buffet style.\"\"\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4c365d",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_df = spark.createDataFrame([['']]).toDF(\"text\")\n",
    "\n",
    "model = nlpPipeline.fit(empty_df)\n",
    "\n",
    "df = spark.createDataFrame(pd.DataFrame({\"text\":text_list}))\n",
    "result = model.transform(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
